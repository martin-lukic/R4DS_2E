---
title: "R4DS_2E_functions"
author: "Martin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13)
```

## Functions - Vector functions

1. Practice turning the following code snippets into functions. Think about what each function does. What would you call it? How many arguments does it need?

```{r Turning code into functions}
mean(is.na(x))
mean(is.na(y))
mean(is.na(z))
# These tell us the average number of missing values, so I would call it avg_missing. It should only take a single value as it's providing a summary

avg_missing <- function(x) {
  mean(is.na(x))
}

x / sum(x, na.rm = TRUE)
y / sum(y, na.rm = TRUE)
z / sum(z, na.rm = TRUE)
# Divides each value of a vector by the total sum of all of its values. Essentially its calculating the proportion of each value

val_prop <- function(x) {
  x / sum(x, na.rm = TRUE)
}

x <- c(3, 5, 15)
val_prop(x)

round(x / sum(x, na.rm = TRUE) * 100, 1)
round(y / sum(y, na.rm = TRUE) * 100, 1)
round(z / sum(z, na.rm = TRUE) * 100, 1)
# Does the same as above but now multiplies the proportion by 100 and rounds to the nearest 1 d.p.

val_rprop <- function(x) {
  round(x / sum(x, na.rm = TRUE) * 100, 1)
}
```

2. In the second variant of rescale01(), infinite values are left unchanged. Can you rewrite rescale01() so that -Inf is mapped to 0, and Inf is mapped to 1?

```{r Rewriting rescale01}
# The code as it was in the book:
rescale01 <- function(x) {
  rng <- range(x, na.rm = TRUE, finite = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

rescale02 <- function(x) {
  x <- case_when(
    x == -Inf ~ 0,
    x == Inf ~ 1,
    .default = x
  )
  rng <- range(x, na.rm = TRUE)
  (x - rng[1]) / (rng[2] - rng[1])
}

x <- c(-Inf, -3:3, Inf)
x

rescale01(x)
rescale02(x)
```

3. Given a vector of birthdates, write a function to compute the age in years.

```{r Age calculator function}
birthdates <- c("01/02/1994", "05-12-2002", "30 4 1945")
lubridate::dmy(birthdates)
today() - lubridate::dmy(birthdates)

age_dmy <- function(bdays) {
  age <- today() - lubridate::dmy(bdays)
  as.duration(age)
}

ages <- age_dmy(birthdates)
View(ages)
```

4. Write your own functions to compute the variance and skewness of a numeric vector. You can look up the definitions on Wikipedia or elsewhere.

```{r Variance and skewness functions}
myvar <- function(x) {
  sum((x - mean(x, na.rm = TRUE))^2) / length(x)
}

x <- c(1, 2, 3, 5)
myvar(x)

skew <- function(x) {
  sd <- sqrt(myvar(x))
  sum((x - mean(x))^3) / (length(x) - 1) * sd^3
}

skew(x)
```

5. Write both_na(), a summary function that takes two vectors of the same length and returns the number of positions that have an NA in both vectors.

```{r both_na}
x <- c(1, 3, 5, NA, NA, 5)
y <- c(NA, 3, 2, NA, NA, 5)

both_na <- function(x, y) {
  if (length(x) != length(y)) {
    return("Both vectors must be the same length")
  }
  
  which(is.na(x) & is.na(y))
}

both_na(x, y)
```

6. Read the documentation to figure out what the following functions do. Why are they useful even though they are so short?

```{r What do the following functions do?}
is_directory <- function(x) {
  file.info(x)$isdir
}
is_readable <- function(x) {
  file.access(x, 4) == 0
}

# is_directory appears to tell us whether the supplied directory path is an existing directory on your computer. This is definitely helpful when wanting to read/write files.
is_directory("C:/Users/M/OneDrive/Documents")
is_directory("C:/Users/M/OneDrive/Documents/ThisDoesntExist")
# It's using information from `file.info` and subsetting by the `isdir` column
file.info("C:/Users/M/OneDrive/Documents")
file.info("C:/Users/M/OneDrive/Documents/ThisDoesntExist")

# Another self-explanatory function, checks if a file is readable. Uses `file.access` which `mode = 4` which just tests for read permission. The reason for the equality check is that `file.access` will return 0 for success and -1 for failure.
is_readable("C:/Users/M/OneDrive/Documents")
file.access("C:/Users/M/OneDrive/Documents", mode = 4)
file.access("C:/Users/M/OneDrive/Documents/ThisDoesntExist", mode = 4)
```

## Functions - Dataframe functions

1. Using the datasets from nycflights13, write a function that:

Finds all flights that were cancelled (i.e. is.na(arr_time)) or delayed by more than an hour.
Something like `flights |> filter_severe()`

```{r Cancelled flights function}
flights |> 
  filter(is.na(arr_time) | dep_delay >= 60)

filter_severe <- function(df) {
  df |> 
    filter(is.na(arr_time) | dep_delay >= 60)
}

flights |> 
  filter_severe()
```

2. Counts the number of cancelled flights and the number of flights delayed by more than an hour.

```{r Number of cancelled flights or delayed by more than an hour}
summarize_severe <- function(df) {
  df |> 
    summarize(
      n_cancelled = sum(is.na(arr_time)),
      n_big_delay = sum(dep_delay >= 60, na.rm = TRUE),
      .groups = "drop"
    )
}

flights |> 
  group_by(dest) |> 
  summarize_severe()
```

3. Finds all flights that were cancelled or delayed by more than a user supplied number of hours:

```{r Better filter_severe function}
filter_severe <- function(df, hours) {
  df |> 
    filter(is.na(arr_time) | dep_delay >= hours * 60)
}

flights |> 
  filter_severe(hours = 3)
```

4. Summarize the weather to compute the minimum, mean, and maximum, of a user supplied variable:

```{r Weather variable summary}
summarize_weather <- function(df, var) {
  df |> 
    summarize(
      min = min({{ var }}, na.rm = TRUE),
      mean = mean({{ var }}, na.rm = TRUE),
      max = max({{ var }}, na.rm = TRUE),
      .groups = "drop"
    )
}

weather |> summarize_weather(temp)
```

5. Converts the user supplied variable that uses clock time (e.g., dep_time, arr_time, etc.) into a decimal time (i.e. hours + (minutes / 60)).

```{r Clock time to decimal time}
standardize_time <- function(df, var) {
  df |> 
    mutate(
      hours = {{ var }} %/% 100,
      minutes = {{ var }} %% 100,
      standard_time = round((hours + (minutes / 60)), 2)
    ) |> 
    select(-c(hours, minutes)) |> 
    relocate(year:day, standard_time)
}

flights |> 
  standardize_time(dep_time)
```

6. For each of the following functions list all arguments that use tidy evaluation and describe whether they use data-masking or tidy-selection: distinct(), count(), group_by(), rename_with(), slice_min(), slice_sample().

Answer: Best way to check if they use data masking or tidy selection is to read the documentation. Also from `vignette("programming", package = "dplyr")` we get useful definitions of what data masking and tidy selection is:

arrange(), count(), filter(), group_by(), mutate(), and summarise() use data masking so that you can use data variables as if they were variables in the environment (i.e. you write my_variable not df$my_variable).

across(), relocate(), rename(), select(), and pull() use tidy selection so you can easily choose variables based on their position, name, or type (e.g. starts_with("x") or is.numeric).

So for example a function that doesn't use tidy evaluation may be the base R function `sum()` as you have to do something like `sum(is.na(flights$arr_delay))` instead of `flights |> sum(is.na(arr_delay))`. The latter is called data masking.

```{r Tidy evaluation or no? Data masking or tidy selection?}
# Note that a function that uses either data-masking or tidy-selection means that it uses tidy evaluation.
# `distinct()`, `count()`, `group_by()` use data-masking
# `slice_min()` and `slice_sample()` both use tidy-selection and data-masking
# `rename_with()` uses tidy-selection

iris <- as_tibble(iris)
rename_with(iris, toupper, starts_with("Petal"))
```

7. Generalize the following function so that you can supply any number of variables to count.

```{r Generalizing a function}
count_prop <- function(df, var, sort = FALSE) {
  df |>
    count({{ var }}, sort = sort) |>
    mutate(prop = n / sum(n))
}

# We should probably use `pick` if we want to accomplish this

count_prop2 <- function(df, vars, sort = FALSE) {
  df |>
    count(pick({{ vars }}), sort = sort) |>
    mutate(prop = n / sum(n))
}

flights |> 
  count_prop2(c(dep_delay, arr_delay))
```

## Functions - Plot functions

1. Build up a rich plotting function by incrementally implementing each of the steps below:

Draw a scatterplot given dataset and x and y variables.
Add a line of best fit (i.e. a linear model with no standard errors).
Add a title.

```{r Plotting function}
general_plot <- function(df, x, y) {
  label <- rlang::englue("A scatterplot of {{x}} on {{y}} with a line of best fit")
  
  df |>
    ggplot(aes(x = {{ x }}, y = {{ y }})) +
    geom_point() +
    geom_smooth(method = "lm", formula = y ~ x, color = "blue", se = FALSE) +
    labs(title = label)
}

flights |> 
  general_plot(dep_delay, arr_delay)
```

## Functions - Style

1. Read the source code for each of the following two functions, puzzle out what they do, and then brainstorm better names.

```{r Better names?}
f1 <- function(string, prefix) {
  str_sub(string, 1, str_length(prefix)) == prefix
}
# This function tells us whether a string has the following supplied prefix or not.

prefix <- "boo"
str_sub("hello", 1, str_length(prefix)) == prefix
str_sub("bootie", 1, str_length(prefix)) == prefix

# Maybe we can call it `has_prefix` or `is_prefix`

f3 <- function(x, y) {
  rep(y, length.out = length(x))
}
# This function repeats y by whatever length x is

x <- c(5, 3, 2, 1, 10)
y <- 1
f3(x, y)

# Maybe we can call it rep_y_by_x_length, but this seems kind of long.
```

2. Take a function that youâ€™ve written recently and spend 5 minutes brainstorming a better name for it and its arguments.

```{r Better name brainstorming}
# I'm not sure since I haven't written my own function recently, so instead lets think about the f1 function above.

has_prefix <- function(string, prefix) {
  str_sub(string, 1, str_length(prefix)) == prefix
}
# The arguments seem perfectly fine.
```

3. Make a case for why norm_r(), norm_d() etc. would be better than rnorm(), dnorm(). Make a case for the opposite. How could you make the names even clearer?

```{r Naming conventions}
# If we specifically thought about wanting a normal distribution function that having them named `norm_r()`, `norm_d()` etc. would be better when using auto complete.
# The opposite may be true if we want to find a random (r) or density (d) distribution.
# We could potentially make the names even clearer by doing something like `rand_norm()`, `dens_norm()` etc. so there is no confusion what these functions are doing.
```

