---
title: "R4DS_2E_numbers"
author: "Martin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13)
```

## Transform - Counts

1. How can you use count() to count the number of rows with a missing value for a given variable?

```{r Counting missing values}
flights |> 
  count(missing_count = is.na(arr_delay)) |> 
  filter(missing_count == TRUE) |> 
  select(n)

# Much easier to just use summarize:

flights |> 
  summarize(missing_count = sum(is.na(arr_delay)))
```

2. Expand the following calls to count() to instead use group_by(), summarize(), and arrange():

a. flights |> count(dest, sort = TRUE)

```{r Not using count a)}
flights |> count(dest, sort = TRUE)

flights |> 
  group_by(dest) |> 
  summarize(
    n = n()
  ) |> 
  arrange(desc(n))
```

b. flights |> count(tailnum, wt = distance)

```{r Not using count b)}
flights |> count(tailnum, wt = distance)

flights |> 
  group_by(tailnum) |> 
  summarize(
    n = sum(distance)
  )
# Looks like arrange isn't needed as the code using `count` is not arranged in any order.
```

## Transform - Numbers

1. Explain in words what each line of the code used to generate Figure 14.1 does.

![](https://r4ds.hadley.nz/numbers_files/figure-html/fig-prop-cancelled-1.png)

```{r Figure 14.1 code explanation}
flights |> 
  group_by(hour = sched_dep_time %/% 100) |> # grouping by hour e.g. 1, 2, 3... This effects future computations
  summarize(prop_cancelled = mean(is.na(dep_time)), n = n()) |> # calculating proportion cancelled and total number of flights
  filter(hour > 1) |> # drops low traffic hours 1-4
  ggplot(aes(x = hour, y = prop_cancelled)) +
  geom_line(color = "grey50") +  # add a line to go through the datapoints
  geom_point(aes(size = n)) # include datapoints and differentiate them by how many total flights for each hour by size
```

2. What trigonometric functions does R provide? Guess some names and look up the documentation. Do they use degrees or radians?

Answer: I imagine cos, sin, tan will be there. When using autocomplete we see, cos, coth, sin, sinh, tan, and tanh. Although cosec, sec and cot aren't there it doesn't really matter as we can always define these on our own using the pre-existing base trigonometric functions. Angles are givin in radians according to documentation.

```{r Base trigonometric functions}
sin(pi/2)
cos(pi)
```

3. Currently dep_time and sched_dep_time are convenient to look at, but hard to compute with because they’re not really continuous numbers. You can see the basic problem by running the code below: there’s a gap between each hour.

flights |> 
  filter(month == 1, day == 1) |> 
  ggplot(aes(x = sched_dep_time, y = dep_delay)) +
  geom_point()
  
Convert them to a more truthful representation of time (either fractional hours or minutes since midnight).

```{r Converting time}
View(flights)

flights |> 
  mutate(
    sched_dep_time_hour = sched_dep_time %/% 100,
    sched_dep_time_min = sched_dep_time %% 100,
    sched_dep_time_hr = sched_dep_time_hour + (sched_dep_time_min / 60),
    dep_delay_hour = dep_delay %/% 100,
    dep_delay_min = dep_delay %% 100,
    dep_delay_hr = dep_delay_hour + (dep_delay_min / 60)
  ) |> 
  filter(month == 1, day == 1) |> 
  ggplot(aes(x = sched_dep_time_hr, y = dep_delay_hr)) +
  geom_point()
```

4. Round dep_time and arr_time to the nearest five minutes.

Answer: To round to something specific like "five minutes" rather than a set number of digits, we have to do some computation within the round function followed by the opposite computation outside of the function

```{r Rounding time}
# Going to use a small sample of times instead
x <- c(517, 518, 521, 555, 558, 601, 622, 2326, 2328, 2325, 2359)
round(x / 5) * 5
# 517/5 goes to 103.4 which is rounded to 103. Then multiplied by 5 we get 515 as required. The only issue currently is if we have times between *58-*59 which round to *60 which we don't want. We want to it round to (*+1)00

# Lets exclude this case by using an if_else statement. There is most likely a much more elegant, but more complicated way to solve this using modulo operator:
if_else((x %% 100) %in% c(58, 59), (x + 100) - (x %% 100), round(x / 5) * 5)

flights |> 
  mutate(
    arr_time = if_else((arr_time %% 100) %in% c(58, 59),
                       (arr_time + 100) - (arr_time %% 100),
                       round(arr_time / 5) * 5),
    dep_time = if_else((dep_time %% 100) %in% c(58, 59),
                       (dep_time + 100) - (dep_time %% 100),
                       round(dep_time / 5) * 5),
  )
```

## Transform - General transformations

1. Find the 10 most delayed flights using a ranking function. How do you want to handle ties? Carefully read the documentation for min_rank().

```{r Ranked function}
x <- c(1, 2, 6, 3, 4, NA)
min_rank(x)
#> 1  2  5  3  4 NA

min_rank(desc(x))
#> 5  4  1  3  2 NA
flights |> 
  mutate(rank = min_rank(desc(dep_delay))) |> 
  arrange(rank) |> 
  filter(rank %in% 1:10)
# We can handle ties by instead using `row_number` so that way if we had two flights with same dep_delay value, the flight that appeared first via row_number will be chosen over the second one.
```

2. Which plane (tailnum) has the worst on-time record?

```{r Worst on-time record}
# To calculate how "on-time" a plane is, we could do this multiple different ways. For example:
#> 1. We simply calculate the sum of arr_delay for each plane
#> 2. Or we can calculate the average arr_delay for each plane to account for the total number of flights of each plane
#> Also note that a plane might only take a very bad route where all other planes also have a large delay, so in this case its not really the planes fault for a bad on-time record, its the destination

flights |> 
  group_by(tailnum) |> 
  summarize(on_time = sum(arr_delay, na.rm = TRUE)) |> 
  arrange(desc(on_time))
# tailnum N15910 has the worst on_time record

flights |> 
  group_by(tailnum) |> 
  summarize(on_time = mean(arr_delay, na.rm = TRUE)) |> 
  arrange(desc(on_time))
# Using second method, tailnum N844MH has the worst on_time record
```

3. What time of day should you fly if you want to avoid delays as much as possible?

```{r Best time of day to avoid delays}
# We should focus on departure times as this is something we have more control over avoiding delays if we are a customer.
flights |> 
  mutate(dep_time = round((dep_time %/% 100) + ((dep_time %% 100) / 60), 0)) |> 
  group_by(dep_time) |> 
  mutate(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) |> 
  ggplot(aes(x = dep_time, y = avg_dep_delay)) +
  geom_line() +
  geom_point()
# Best time to fly is in the very early hours of the morning around 5 when all the delay congestion from the previous day has dissipated.
```

4. What does flights |> group_by(dest) |> filter(row_number() < 4) do? What does flights |> group_by(dest) |> filter(row_number(dep_delay) < 4) do?

```{r What do these filters do?}
flights |> group_by(dest) |> filter(row_number() < 4)
# First groups by destination and then filter to the first three row numbers where these destinations appear. For example if dest is ATL, then the first three appearences of this destination within the dataset will be filtered based off of this. ATL appears once at row 5, a second time at row 19 and a third time at row 24 in the original dataset. These rows will be pulled.

flights |> group_by(dest) |> filter(row_number(dep_delay) < 4)
# Similar to above. We just have an added caviat that `row_number` is now based off `dep_delay`. Take the destination "AVL" for example. The first three rows with the lowest values in dep_delay (i.e. those with the smallest departure "delay") will be selected. This is similar for all the other destinations. Look at the added code below and run it piecemeal to see what `row_number` is doing.

flights |> group_by(dest) |> mutate(row_number(dep_delay) < 4)
flights |>  
  group_by(dest) |>  
  mutate(rnum = row_number(dep_delay)) |> 
  filter(dest == "AVL") |> 
  arrange(rnum) |> 
  relocate(dep_delay, dest, rnum)
```

5. For each destination, compute the total minutes of delay. For each flight, compute the proportion of the total delay for its destination.

```{r Total destination delay in minutes}
# arr_delay should only matter in this context

flights |> 
  group_by(dest) |> 
  mutate(total_arr_delay = sum(arr_delay, na.rm = TRUE))

# If we want to compute the proportion of the total delay for a flights destination, we will need to get the total air time for each flight. 
flights |> 
  filter(arr_delay >= 0) |> # Can't have a negative proportion, and we don't really need to consider flights that weren't actually delayed.
  mutate(arr_delay_prop = arr_delay / air_time)
```

6. Delays are typically temporally correlated: even once the problem that caused the initial delay has been resolved, later flights are delayed to allow earlier flights to leave. Using lag(), explore how the average flight delay for an hour is related to the average delay for the previous hour.

```{r Temporal correlation}
hr_delay_flights <- flights |> 
  mutate(hour = dep_time %/% 100) |> 
  group_by(year, month, day, hour) |> 
  summarize(
    dep_delay = mean(dep_delay, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  ) |> 
  filter(n > 5) |> 
# For some reason there are random missing values for some days during the late hours of the day. This is because dep_time == NA so I imagine they cancel alot of flights later on in the day to prevent congestion for the next day of flights. I will remove these for now as it'll be easier to see if previous delay times effect future delay times.
  filter(!is.na(hour))

# Another issue I see is now all hours aren't even consecutive. Take row 218, we have an hour of 0. The previous hour was 21 of the previous day, and the next hour is at 5. Take a look at the following code:

hr_delay_flights |> 
  group_by(hour) |> 
  summarize(
    n = n(),
    .groups = "drop"
  )
# hours 0-2 look like we should drop them but I'm not sure. Instead I'm going to look through the solution in `transform.Rmd`
```

```{r Temporal correlation sol-n p1}
# This calculates the departure delay of the preceding flight from the same airport.
lagged_delays <- flights %>%
  arrange(origin, month, day, dep_time) %>%
  group_by(origin) %>%
  mutate(dep_delay_lag = lag(dep_delay)) %>%
  filter(!is.na(dep_delay), !is.na(dep_delay_lag))
```

This plots the relationship between the mean delay of a flight for all values of the previous flight.
For delays less than two hours, the relationship between the delay of the preceding flight and the current flight is nearly a line.
After that the relationship becomes more variable, as long-delayed flights are interspersed with flights leaving on-time.
After about 8-hours, a delayed flight is likely to be followed by a flight leaving on time.

```{r Temporal correlation sol-n p2}
lagged_delays %>%
  group_by(dep_delay_lag) %>%
  summarise(dep_delay_mean = mean(dep_delay)) %>%
  ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 1500, by = 120)) +
  labs(y = "Departure Delay", x = "Previous Departure Delay")
```

The above plot is for all three airport origins. When faceting them by origin the relationships all look very similar

```{r Temporal correlation sol-n p3}
lagged_delays %>%
  group_by(origin, dep_delay_lag) %>%
  summarise(dep_delay_mean = mean(dep_delay)) %>%
  ggplot(aes(y = dep_delay_mean, x = dep_delay_lag)) +
  geom_point() +
  facet_wrap(~ origin, ncol = 1) +
  labs(y = "Departure Delay", x = "Previous Departure Delay")
```

7. Look at each destination. Can you find flights that are suspiciously fast (i.e. flights that represent a potential data entry error)? Compute the air time of a flight relative to the shortest flight to that destination. Which flights were most delayed in the air?

```{r Suspiciously fast flights?}
flights |> 
  group_by(dest) |> 
  summarize(
    air_time = air_time
  ) |> 
  arrange(air_time)
# To see if an air_time of only 20 minutes is actually a data entry error we could look at the following: What is the distance between the origin and destination? How many other planes had a similarly low air_time? If only one plane had a much lower air_time then other planes then maybe we can argue this is a data entry error.

flights |> 
  group_by(origin, dest, tailnum) |> 
  ggplot(aes(y = air_time, x = dest)) +
  theme(axis.text.x = element_text(angle = 90)) +
  geom_boxplot()
# I tried this way but its honestly pretty messy to find fast flights. Look at the standardization technique used in the community sol-n's in `transform.Rmd`
```

8. Find all destinations that are flown by at least two carriers. Use those destinations to come up with a relative ranking of the carriers based on their performance for the same destination.

```{r Two plus carrier destinations p1}
multiple_carriers <- flights |> 
  group_by(dest, carrier) |> 
  summarize() |> 
  filter(table(dest) >= 2) |> 
  ungroup()
  
unique(multiple_carriers$dest)
# These are all the destinations that are flown by at least two carriers
```

Lets base performance on how many destinations each carrier services and rank them by that metric

```{r Two plus carrier destinations p2}
performance_flights <- flights |> 
  filter(dest %in% unique(multiple_carriers$dest)) |> 
  group_by(carrier) |> 
  summarize(n_distinct = n_distinct(dest)) |> 
  mutate(rank = min_rank(desc(n_distinct))) |> 
  arrange(rank) |> 
  ungroup()

performance_flights |> 
  ggplot(aes(x = rank, y = carrier)) +
  geom_bar(stat = "identity") +
  labs(title = "Rank of Carriers for Different Destinations",
       x = "Rank",
       y = "Carrier") +
  theme_minimal()

# Carrier EV services the most amount of destinations
```

## Transform - Numeric summaries

1. Brainstorm at least 5 different ways to assess the typical delay characteristics of a group of flights. When is mean() useful? When is median() useful? When might you want to use something else? Should you use arrival delay or departure delay? Why might you want to use data from planes?

Mean is useful when the distribution is generally symmetric, median is better when skewed distribution or large outliers.

<!-- 
**TODO** (Add a better explanation and some examples)
-->

```{r Typical delay characteristics brainstorming}
flights |> 
  group_by(tailnum) |> 
  mutate(avg_arr_delay = mean(arr_delay, na.rm = TRUE))

n_distinct(flights$tailnum)
```

2. Which destinations show the greatest variation in air speed?

If we want to look at variation in air speed we should standardize air speed. The destinations which show the greatest variation in air speed will be those three or more standard deviations above or below the mean.

```{r Variations in air speed using mean}
flights |> 
  group_by(dest) |> 
  mutate(air_speed = distance / air_time,
         mean_air_speed = mean(air_speed, na.rm = TRUE),
         sd_air_speed = sd(air_speed, na.rm = TRUE),
         std_air_speed = (air_speed - mean_air_speed) / sd_air_speed) |> 
  filter(std_air_speed >= mean_air_speed + 3 * sd_air_speed |
         std_air_speed <= mean_air_speed - 3 * sd_air_speed)
# Distribution must clearly be very skewed, lets use IQR method instead
```

```{r Variations in air speed using median}
flights |> 
  mutate(
    air_time_median = median(air_time, na.rm = TRUE),
    air_time_iqr = IQR(air_time, na.rm = TRUE),
    n = n(),
    q999 = quantile(air_time, 0.999, na.rm = TRUE), q001 = quantile(air_time, 0.001, na.rm = TRUE),
    air_time_standard = (air_time - air_time_median) / air_time_iqr
    ) |> 
  filter(air_time >= q999 | air_time <= q001) |> 
  group_by(dest) |> 
  summarize(n = n())
# Destinations ALB, BDL, BOS, HNL and PHL have the largest variations in air_time. ALB and BOS only have a total of two rows each that agree with the above filter statement so they are maybe not that great to include in destinations that have high variation. The other three have counts in the hundreds.
```

3. Create a plot to further explore the adventures of EGE. Can you find any evidence that the airport moved locations? Can you find another variable that might explain the difference?

If the airport moved locations then I imagine we can detect this by looking at the distance column for each origin and destination combination.

```{r EGE adventures}
flights_EGE <- flights |> 
  filter(dest == "EGE")

View(flights_EGE)

flights_EGE |> 
  group_by(origin, dest, distance) |> 
  summarize(
    n = n()
  ) |> 
  ggplot(aes(origin, distance)) +
  geom_point() +
  labs(
    title = "Distance from origin to EGE destination",
    subtitle = "EGE airport appears to have moved",
    x = "Origin",
    y = "Distance"
  )
```

