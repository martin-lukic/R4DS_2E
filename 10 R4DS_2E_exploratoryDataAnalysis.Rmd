---
title: "R4DS_2E_exploratoryDataAnalysis"
author: "Martin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggcorrplot)
library(lvplot)
library(ggbeeswarm)
library(nycflights13)
```

## Exploratory data analysis - Unusual values

1. Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth.

```{r Diamonds dimensions exploration}
# I would expect diamonds to have similar lengths and widths due to their overall symmetry and maybe a higher depth in respect to length and width. My first thought is that x and y are length and width respectively and z will be depth.

ggplot(diamonds, aes(x = x)) + 
  geom_histogram(binwidth = 0.5) +
  xlim(c(1, 10))

ggplot(diamonds, aes(x = y)) + 
  geom_histogram(binwidth = 0.5) +
  xlim(c(1, 10))

ggplot(diamonds, aes(x = z)) + 
  geom_histogram(binwidth = 0.5) +
  xlim(c(1, 10))

# Both plots of x and y counts are extremely similar, which suggests that x and y are length and width respectively. The values for z suprise me a little then what I invisioned. Looks like the depth of diamonds are slightly lower than that of the length and width of the diamond.

diamonds |> 
  filter(between(y, 1, 10) & between(x, 1, 10)) |> 
  ggplot(aes(x = x, y = y)) + 
    geom_point()
```

2. Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.)

```{r Diamonds price distribution}
ggplot(diamonds, aes(x = price)) + 
  geom_histogram(binwidth = 50)
# The above shows an unusual dip somewhere between 0-2500 in price. Lets try zoom in on it

ggplot(diamonds, aes(x = price)) + 
  geom_histogram(binwidth = 10) +
  xlim(c(1400, 1600))
# It appears no prices are between 1460-1540 in terms of price. This is strange. Some sort of follow up would be needed as to why this is the case.
```

3. How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference?

```{r Carat diamonds}
diamonds |> 
  summarize(
    n = n(),
    .by = carat
  ) |> 
  filter(carat %in% c(0.99, 1))

# We see that there are 1558 1 carat diamonds compared to only 23 0.99 carat diamonds. This is strange. I imagine the cause of the difference is due to rounding up.
```

4. Compare and contrast coord_cartesian() vs. xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows?

```{r Coordinate Cartestion vs x Limit & y Limit}
# Lets look at an earlier example:
ggplot(diamonds, aes(x = price)) + 
  geom_histogram(binwidth = 10) +
  xlim(c(1400, 1600))
# We can see in the warning for the above plot that using `xlim()` or `ylim()` removes any rows of values that aren't contained within the range of the limit.

ggplot(diamonds, aes(x = price)) + 
  geom_histogram(binwidth = 10) +
  coord_cartesian(xlim = c(1400, 1600))
# We can see this isn't the case for `coord_cartesian()` as we have some values below 1400 and above 1600. This seems to also effect the yaxis limit too going from 0-400 instead of 0-175


ggplot(diamonds, aes(x = price)) + 
  geom_histogram() +
  xlim(c(1400, 1600))

ggplot(diamonds, aes(x = price)) + 
  geom_histogram() +
  coord_cartesian(xlim = c(1400, 1600))

# It seems to set the binwidth automatically to 30. Although for an unknown reason this messes up coord_cartestian. Also not that for xlim we can see how bars that will only be half shown in the zoom in due to the binwidth argument will be removed altogether rather than shown.
```

## Exploratory data - Unusual values

1. What happens to missing values in a histogram? What happens to missing values in a bar chart? Why is there a difference in how missing values are handled in histograms and bar charts?

```{r Differences in missing values}
diamonds2 <- diamonds |> 
  mutate(y = if_else(y < 3 | y > 20, NA, y))

ggplot(diamonds2, aes(x = y)) +
  geom_histogram(binwidth = 0.01)
# Says it removed 9 rows containing non-finite values (stat_bin()). Essentially missing values are removed when the number of observations in each bin are calculated

# For the following mutate, we use `runif()` function to randomly generate values from 0 to 1. So as you can see some values will end up as missing values.
diamonds %>%
  mutate(cut = if_else(runif(n()) < 0.1, NA_character_, as.character(cut))) %>%
  ggplot() +
  geom_bar(mapping = aes(x = cut))
# As you can see `geom_bar()` treats NA as its own separate category
```

2. What does na.rm = TRUE do in mean() and sum()?

```{r na.rm in Mean and Sum}
mean(c(1, 7, NA, 10), na.rm = TRUE) # It ignores the missing value when summing all values for the numerator and for the denominator, effectively calculating the mean of 3 values that sum to 18.

sum(c(1, 7, NA, 10), na.rm = TRUE) # Expected behavior.

# i.e. it removes missing values prior to calculating these values.
```

3. Recreate the frequency plot of scheduled_dep_time colored by whether the flight was cancelled or not. Also facet by the cancelled variable. Experiment with different values of the scales variable in the faceting function to mitigate the effect of more non-cancelled flights than cancelled flights.

```{r Scheduled departure time | Frequency Plot}
cancelled_flights <- nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time)) + 
  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)

cancelled_flights +
  facet_wrap(~cancelled, scales = "free_y")
# We get a much better picture when we set `scales = "free_y"`. We can see that generally when the number of non-cancelled flights goes up (i.e. number of scheduled flights at a particular time), the greater number of cancelled flights. Logically, the more number of flights corresponding to more cancelled flights makes sense.
```

## Exploratory data - Covariation

### A categorical and a numerical variable

1. Use what you’ve learned to improve the visualization of the departure times of cancelled vs. non-cancelled flights.

```{r Improving cancelled vs. non-cancelled flights}
nycflights13::flights |> 
  mutate(
    cancelled = is.na(dep_time),
    sched_hour = sched_dep_time %/% 100,
    sched_min = sched_dep_time %% 100,
    sched_dep_time = sched_hour + (sched_min / 60)
  ) |> 
  ggplot(aes(x = sched_dep_time, y = after_stat(density))) + 
  geom_freqpoly(aes(color = cancelled), binwidth = 1/4)

# Making the y axis based off of density rather than count shows a much better picture for cancelled flights vs non-cancelled flights. It shows the similar trend that we discovered previously, that the density of cancelled flights closely follows the density of non-cancelled flights
```

2. Based on EDA, what variable in the diamonds dataset appears to be most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive?

Answer: Given where we currently are in the book, I don't think making a bunch of scatterplots of different variables with price on the y axis is recommended. Instead I'll look on line to find out how to easily calculate correlations between variables. Lets compute the correlations between all continuous variables.

```{r Diamonds EDA}
num_diamonds <- diamonds |> 
  select(-c("cut", "color", "clarity"))

cor(num_diamonds) |> 
  ggcorrplot()

ggplot(diamonds, aes(carat, price)) +
  geom_point()

# We can see the carat is strongly correlated with price and despite me having no knowledge of pricing diamonds, the term 'carat' is thrown around a lot when pricing a diamond so its safe to say this is an important variable in predicting the price of a diamond

ggplot(diamonds, aes(x = carat, y = after_stat(density))) + 
geom_freqpoly(aes(color = cut), binwidth = 1/4)

# The majority of Ideal cuts are between 0 - 0.3 carat. The other cut categories seem to be pretty similar to one another. Given that we know that carat is positively correlated this would suggest that most ideal diamonds will be of a lower price.

ggplot(diamonds, aes(cut, carat)) +
  geom_boxplot()

# Through this boxplot we can see that this is the case. On average diamonds that are consider "Fair" (i.e. the worst quality) on average has a higher carat value than all other cuts.

#There is a slight negative relationship between carat and cut.
# Noticeably, the largest carat diamonds have a cut of "Fair" (the lowest).
# 
# This negative relationship can be due to the way in which diamonds are selected for sale.
# A larger diamond can be profitably sold with a lower quality cut, while a smaller diamond requires a better cut.
```

3. Instead of exchanging the x and y variables, add coord_flip() as a new layer to the vertical boxplot to create a horizontal one. How does this compare to exchanging the variables?

```{r Coordinate Flip}
ggplot(mpg, aes(x = fct_reorder(class, hwy, median), y = hwy)) +
  geom_boxplot() +
  coord_flip()

ggplot(mpg, aes(x = hwy, y = fct_reorder(class, hwy, median))) +
  geom_boxplot()

# They appear to be indentical 
```

4. One problem with boxplots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of “outlying values”. One approach to remedy this problem is the letter value plot. Install the lvplot package, and try using geom_lv() to display the distribution of price vs. cut. What do you learn? How do you interpret the plots?

```{r Letter Value Plot}
ggplot(diamonds, aes(cut, price)) +
  geom_lv()

ggplot(diamonds, aes(cut, price)) +
  geom_boxplot()

# Letter value plots appear to give more detailed information beyond the central 50% of the data that a boxplot does by providing similar quantile boxes outside the central 25%-75% quartiles. For example I can see that there are significantly less diamonds that are "Fair" and expensive due to the size of each box compared to that of say, "Premium", "Ideal" diamonds etc.
```

5. Create a visualization of diamond prices vs. a categorical variable from the diamonds dataset using geom_violin(), then a faceted geom_histogram(), then a colored geom_freqpoly(), and then a colored geom_density(). Compare and contrast the four plots. What are the pros and cons of each method of visualizing the distribution of a numerical variable based on the levels of a categorical variable?

```{r Different diamond prices plots}
ggplot(diamonds, aes(x = cut, y = price)) +
  geom_violin()
# I heard violin plots are basically useless, but in this instance they are pretty good at showing how there are alot more "Ideal" diamonds at a price of around 1000-2000. This ties back into a lot of what we said previously that the best cut diamonds do not mean the most pricey.

ggplot(diamonds, aes(x = price)) +
  geom_histogram() +
  facet_wrap(~cut)
# This is useful is we want a general overview of the count for each cut for each price. If we want to compare specific bins this is much harder to do.

ggplot(diamonds, aes(x = price)) +
  geom_freqpoly(aes(color = cut))
# I would say this is a bit more useful than the above plot to get a general overview of the counts of different prices for different cuts. Again if the faceted variable has relatively similar counts it can obscure the relationship we want to show.

ggplot(diamonds, aes(x = price)) +
  geom_density(aes(color = cut))
# This is really good if we have wildly different counts for different cuts. For example in the above two plots we see that if the total count for Fair diamonds is low. But since we now are using a density plot, we see some hidden information that was obscured previously. The majority of Fair diamonds are around the ~2500 price point which is higher than other cuts. This ties in to much of what we've been talking about. I think this is generally better than the violin plot.
```

6. If you have a small dataset, it’s sometimes useful to use geom_jitter() to avoid overplotting to more easily see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does.

Answer: Lets use the package prefix 'ggbeeswarm::' along with the autocomplete function by pressing TAB to see different geom functions ggbeeswarm provides

```{r ggbeeswarm geoms}
# Lets use some examples to show the difference without using the beeswarm package:
ggplot(mpg, aes(drv, hwy)) +
  geom_point()

ggplot(mpg, aes(drv, hwy)) +
  ggbeeswarm::geom_beeswarm()
# Simply offsets points so we can see where overlapping is

ggplot(mpg, aes(drv, hwy)) +
  ggbeeswarm::geom_quasirandom()
# The offsetting is not by the same distance between each point, instead it is now a random distance.
```

### Two categorical variables

1. How could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut?

```{r Rescale by count}
# Original:
diamonds |> 
  count(color, cut) |>  
  ggplot(aes(x = color, y = cut)) +
  geom_tile(aes(fill = n))

# Ordered by total count for each color in ascending order
diamonds |> 
  count(color, cut) |>  
  ggplot(aes(x = fct_reorder(color, n), y = cut)) +
  geom_tile(aes(fill = n))
```

2. What different data insights do you get with a segmented bar chart if color is mapped to the x aesthetic and cut is mapped to the fill aesthetic? Calculate the counts that fall into each of the segments.

```{r Segmented bar chart}
ggplot(diamonds, aes(x = color, fill = cut)) +
  geom_bar()
# We see the different cut spreads for different colors. Interestingly for the J color Very Good, Premium and Ideal cuts look to be approximately the same count, compared to the other colors, it is clear that Ideal has the highest count for each color, followed by Premium, Very Good, Good and finally Fair. It doesn't really seem like the color assigned to a diamond is based off the type of cut.

diamonds |> 
  count(color, cut)
```

3. Use geom_tile() together with dplyr to explore how average flight departure delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it?

```{r Geometric Tile}
flights2 <- nycflights13::flights |> 
  group_by(dest, month) |> 
  mutate(dest_month_delay = mean(dep_delay, na.rm = TRUE)) |> 
  ggplot(aes(x = dest, y = factor(month))) +
  geom_tile(aes(fill = dest_month_delay))
# Immediate problem is that there are a ton of destinations, thus unreadable ticks on the x axis.

flights3 <- flights2 +
  coord_flip()
# Slightly better. But still a lot of overlap

flights3 +
  scale_x_discrete(guide = guide_axis(n.dodge = 3))
# Have to use `scale_x` rather than `scale_y` since we used `coord_flip` and this appears to be the behavior. his seems to be the best I can do with this many y-axis tick labels without changing the aspect ratio of the entire plot.
# We could also make a bunch of changes such as removing missing values (We would have to do this to only select airports which have flights for every single month) as well as ordering the destinations by some sort of important variable, which is this case it might be by overall total departure delay for each airport. Also appropriate labels and titles etc.

flights |> 
  group_by(month, dest) |> 
  summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) |> 
  group_by(dest) |> 
  filter(n() == 12) |> 
  ungroup() |> 
  mutate(dest = fct_reorder(dest, dep_delay)) |> 
  ggplot(aes(x = factor(month), y = dest)) +
  geom_tile(aes(fill = dep_delay)) +
  labs(
    title = "Flight delays overview",
    subtitle = "By month and destination",
    caption = "Sourced from nycflights13 flights dataset",
    x = "Month",
    y = "Destination (Abbreviated)"
  ) +
  scale_y_discrete(guide = guide_axis(n.dodge = 3))
```

### Two numerical variables

1. Instead of summarizing the conditional distribution with a boxplot, you could use a frequency polygon. What do you need to consider when using cut_width() vs. cut_number()? How does that impact a visualization of the 2d distribution of carat and price?

```{r Conditional frequency polygon}
smaller <- diamonds |> 
  filter(carat < 3)

ggplot(smaller, aes(color = cut_number(carat, 5), x = price)) + 
  geom_freqpoly()
# `cut_width` automatically chooses appropriate bins for us while with `cut_number` we must specify the number of bins we want. We need sufficient data values to produce the specified number of bins we want else it will return an error
```

2. Visualize the distribution of carat, partitioned by price.

```{r Distributon of carat partitioned by price}
ggplot(smaller, aes(color = cut_width(price, 5000, boundary = 0), x = carat)) +
  geom_freqpoly()

ggplot(smaller, aes(x = cut_number(price, 10), y = carat)) +
  geom_boxplot() +
  coord_flip() +
  xlab("Price")
```

3. How does the price distribution of very large diamonds compare to small diamonds? Is it as you expect, or does it surprise you?

```{r Price distribution of large diamonds}
ggplot(diamonds, aes(x, price)) +
  geom_point()

ggplot(diamonds, aes(y, price)) +
  geom_point()

ggplot(diamonds, aes(z, price)) +
  geom_point()
# I'm going to define very large diamonds as diamonds that have a length of greater than 9mm. I'm going to define small diamonds as those that have a length of less than 4 mm but also I'm going to remove obvious data entry errors of those of 0mm

vlarge_diamonds <- diamonds |> 
  filter(x >= 9)
small_diamonds <- diamonds |> 
  filter(between(x, 0.5, 4))

ggplot(vlarge_diamonds, aes(x = price)) +
  geom_freqpoly()
# very large diamonds are much more variable in their pricing, with a greater spike in count near the high end prices

ggplot(small_diamonds, aes(x = price)) +
  geom_freqpoly()
# Small diamonds don't break the $750 limit and seem to be significantly less variable in terms of their pricing with more diamonds at the ~$500 range.

# The results dont seem that suprising.
```

4. Combine two of the techniques you’ve learned to visualize the combined distribution of cut, carat, and price.

```{r Cut + Carat + Price distribution}
# Using something similar to Chunk 18
ggplot(diamonds, aes(x = cut_number(carat, 5), y = price, colour = cut)) +
  geom_boxplot()
```

5. Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the following plot have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately. Why is a scatterplot a better display than a binned plot for this case?

```{r 2D vs 1D Plots}
diamonds |> 
  filter(x >= 4) |> 
  ggplot(aes(x = x, y = y)) +
  geom_point() +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))

# Examining them separately to see:
ggplot(diamonds, aes(y = x)) +
  geom_boxplot()

ggplot(diamonds, aes(y = y)) +
  geom_boxplot()
# We can see a lot of outliers at >9mm, but when comparing x & y together they do not look like outliers.

diamonds |> 
  filter(x >= 4) |> 
  ggplot(aes(x = x, y = y)) +
  geom_boxplot() +
  coord_cartesian(xlim = c(4, 11), ylim = c(4, 11))
# We can see the issue with a binned plot. It obscures outliers which are present when x & y have some sort of relationship since the 50% quartile box simplifies this information too much. In fact it presents outliers which fit the strong relationship between x & y, which we don't want to remove.
```

6. Instead of creating boxes of equal width with cut_width(), we could create boxes that contain roughly equal number of points with cut_number(). What are the advantages and disadvantages of this approach?

```{r Cut Number advantages & disadvantages}
smaller <- diamonds |> 
  filter(carat < 3)

ggplot(smaller, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_width(carat, 0.1)))

ggplot(smaller, aes(x = carat, y = price)) + 
  geom_boxplot(aes(group = cut_number(carat, 20)))

# Some advantages are: for smaller amounts of data within each`cut_width` box, there is an increase in variability. This is not the case for `cut_number` whose boxes have general the same amount of variability, thus providing a more reliable insight into a relationship we may be interested in uncovering.
# Some disadvantages are: There may be many points within a small interval, which creates tiny boxplots in comparison to the rest (see diamonds with carats of around 1) thus a worse visualization overall.
```

