---
title: "R4DS_2E_dataTransformation"
author: "Martin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(nycflights13)
```

## Data Transformation - Rows

1. In a single pipeline for each condition, find all flights that meet the condition:
- Had an arrival delay of two or more hours
- Flew to Houston (IAH or HOU)
- Were operated by United, American, or Delta
- Departed in summer (July, August, and September)
- Arrived more than two hours late, but didn’t leave late
- Were delayed by at least an hour, but made up over 30 minutes in flight


```{r Conditional statements}
flights |> 
  filter(arr_delay >= 120)
flights |> 
  filter(dest %in% c("IAH", "HOU"))
flights |> 
  filter(carrier %in% c("UA", "AA", "DL")) # Look at documentation for what each abbrevation is. Says to look at airlines.
flights |> 
  filter(month %in% c(7, 8, 9))
flights |> 
  filter((arr_delay > 120) & (dep_delay <= 0))
# This next one is slightly more complicated. To do this we want to get flights with a depature delay of greater than or equal to 60 minutes. We can tell if a flight "made up over 30 minutes in flight" if the arrival delay is 30 minutes or less than the respective departure delay for the flight.
flights |> 
  filter((dep_delay >= 60) & (arr_delay <= dep_delay - 30))
```
2. Sort flights to find the flights with longest departure delays. Find the flights that left earliest in the morning.

```{r Longest departure}
long_dep <- flights |> 
  arrange(desc(dep_delay)) |> 
  head(25)

long_dep |> 
  arrange(hour, minute)
# So for example the flight that left earliest is flight 2047, tailnum N6716C at a time of 7:59
```

3. Sort flights to find the fastest flights. (Hint: Try including a math calculation inside of your function.)

```{r Fastest flights (Re-do)}
# There could be a few ways to calculate this depending on what you want:
# - Fastest flight in terms of the speed of the plane. We would need to know the distance between the origin of the plane and the destination to be able to calculate its speed
# - Or we simply want the shortest `airtime` to indicate the fastest flights.
# However the second one would not need a "math calculation" as the Hint indicates. Other possibilities to find the "Fastest flight" that would include a "math calculation" may include:
# - sched_arr_time - sched_dep_time
# - arr_time - dep_time
# - dep_delay - arr_delay
# I'll choose `arr_delay - dep_delay` so I can see how each flight managed to make up time while in the air.

flights |> 
 arrange(desc(dep_delay - arr_delay))
# So for the first flight. despite being delayed by almost 4 hours, managed to make up about 2 hours in air time.

# Despite what I said above, we can actually calculate speed since there is a distance variable in flights

flights |> 
  arrange(desc(distance / air_time * 60))
# The above calculates the speed in mph
```

4. Was there a flight on every day of 2013?

```{r Every day 2013}
flights |> 
  distinct(year, month, day) |> 
  nrow()
# 365 rows for each day of 2013. So yes it appears there was a flight on every day of 2013
```

5. Which flights traveled the farthest distance? Which traveled the least distance?

```{r Farthest/Least distance}
flights |> 
  arrange(desc(distance)) |> 
  head()

flights |> 
  arrange(distance) |> 
  head()
```

6. Does it matter what order you used filter() and arrange() if you’re using both? Why/why not? Think about the results and how much work the functions would have to do.

```{r Filter/Arrange order}
flights |> 
  filter(arr_delay >= 900) |> 
  arrange(arr_delay)

flights |> 
  arrange(arr_delay) |> 
  filter(arr_delay >= 900)

# Based on the above example, order doesn't seem to matter, which logically makes sense if you think about what these functions are doing. I would guess the second example is slightly more laborious for the computer, as it has to arrange every single row first, then we filter the dataframe by some condition. The first example filters the dataframe by some condition first then the computer has to arrange this smaller subset of the original dataframe.
```

## Data Transformation - Columns

1. Compare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?

```{r Departure relation}
# I would expect that dep_delay should be related to the difference between sched_dep_time and dep_time. If the recorded dep_delay is accurate I would expect the difference between sched_dep_time & dep_time and dep_delay to be zero
# dep_time and sched_dep_time are both in HHMM format unlike dep_delay so we have to reconcile this. The calculation that we will need to use is most likely using the modulo operator which we haven't seen yet so I will wait to do this later on in the book
```

2. Brainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.

```{r Select brainstorming}
flights |> 
  select(dep_time, dep_delay, arr_time, arr_delay)
# There are a bunch of other ways. We could fo dep_time:arr_delay and drop the scheduled time columns, we could remove every column that is not dep_time, dep_delay, arr_time or arr_delay, but all these other methods seem much more tedious and unnecessary than the simple select statement above.
```

3. What happens if you specify the name of the same variable multiple times in a select() call?

```{r Specifying same variable}
flights |> 
  select(dep_time, dep_time, arr_time)
# It ignores the fact that the same variable was used multiple times and simply acts as though the variable was called upon  once.
```

4. What does the any_of() function do? Why might it be helpful in conjunction with this vector?

```{r Any of}
variables <- c("year", "month", "day", "dep_delay", "arr_delay")
flights |> 
  select(any_of(variables))
# `any_of()` must be used with a selecting function. It can be helpful since we can specify variables outside of our pipe function for enhanced readability but from the documentation it can also be especially useful with negative selections, when you would like to make sure a variable is removed
```

5. Does the result of running the following code surprise you? How do the select helpers deal with upper and lower case by default? How can you change that default?

```{r Suprise result?!}
flights |> select(contains("TIME"))
# It does surprise me a little. The text within `contains` is not case sensitive by default which can cause potential problems. `contains` has the default argument of `ignore.case = TRUE` so we simply set it to FALSE
flights |> select(contains("TIME", FALSE))
```

6. Rename air_time to air_time_min to indicate units of measurement and move it to the beginning of the data frame.

```{r Renaming air_time}
flights |> 
  relocate(air_time_min = air_time)
```

7. Why doesn’t the following work, and what does the error mean?

```{r Why doesn't this work?}
flights |> 
  select(tailnum) |> 
  arrange(arr_delay)
# Select creates a new dataframe solely with the variable tailnum as specified, so when we call on the arrange function to arrange by arr_delay this simply isn't possible as arr_delay isn't present in our new subsetted dataframe.
```

## Data Transformation - Groups

1. Which carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights |> group_by(carrier, dest) |> summarize(n()))

```{r Worst avg delays}
# We can choose dep_delay or arr_delay. I will choose arr_delay as delayed time when departing can be made up through air time.
flights |> 
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    .by = carrier
  ) |> 
  arrange(desc(avg_delay))
# Carrier F9 has the worst average delay of about 22 minutes
```

```{r Bad airports vs. bad carriers}
flights |> group_by(carrier, dest) |> summarize(n())
# Looking over the above and finding the carrier F9, we see that the F9 carrier only has the destination of DEN. So it appears that there is equal likelihood that the airport that the F9 carrier is leaving from is to blame for the large amount of delays. However it is hard to say for certain, we would probably want to look at the average delay of each destination. If DEN has high average delay then this is further supporting evidence that DEN is a bad airport in terms of delays.

flights |> 
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    .by = dest
  ) |> 
  arrange(desc(avg_delay))
# DEN is about the 49th highest airport in terms of arr_delay, at a value of 8.61. This is a stark difference from the F9 delay of 22, so seemingly it might actually be the carrier's fault in this situation for the delay. But again, I'm not 100% sure how you would go about identifying whether its the carrier or airport fault.
```

2. Find the flights that are most delayed upon departure from each destination.

```{r Most delayed upon departure}
# We'll have to use dep_delay in this instance since we are looking at MOST delayed UPON departure. Note there are 105 unique destinations
flights |> 
  group_by(dest) |> 
  slice_max(dep_delay, n = 1) |> 
  relocate(dest, dep_delay)
```

3. How do delays vary over the course of the day. Illustrate your answer with a plot.

```{r Delays over the day}
# I'll group by each hour and choose arr_delay over dep_delay due to reasons mentioned previously
flights |> 
  summarize(
    avg_delay = mean(arr_delay, na.rm = TRUE),
    .by = hour
  ) |> 
ggplot(aes(x = hour, y = avg_delay)) +
geom_line() +
scale_x_continuous(breaks = seq(5, 24), limits = c(5, 24)) # Ignore below 5 am since missing values
# Bit of a rudimentary plot, however we can see that flights leave early when its early in the morning. Then after 10am the delays start to increase and appear to fall abit after 9pm. I assume most delays clear by the next day's morning.
```

4. What happens if you supply a negative n to slice_min() and friends?

```{r Negative n - Slice_min}
flights |> 
  group_by(carrier) |> 
  slice_min(arr_delay, n = -3)
# When supplying a negative n to slice_min it appears to act as the smallest possible value that n can take (the value of 1)
```

5. Explain what count() does in terms of the dplyr verbs you just learned. What does the sort argument to count() do?

```{r Count}
# Count tells us the number of observations for the supplied arguments that we give it (Through grouping for example)
# The sort argument is default as FALSE. If set to TRUE it will show the largest groups at the top (Essentially its like using arrange but without the extra step of using that function)

flights |> 
  count(dest, sort = TRUE)
flights |> 
  count(dest) |> 
  arrange(desc(n))
```

6. Suppose we have the following tiny data frame:

df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)

a. Write down what you think the output will look like, then check if you were correct, and describe what group_by() does.

df |>
  group_by(y)

```{r Tiny dataframe a)}
df <- tibble(
  x = 1:5,
  y = c("a", "b", "a", "a", "b"),
  z = c("K", "K", "L", "L", "K")
)
# It will look like a dataframe with 3 columns (variables) and 5 rows (observations)
# group_by allows us to group a dataframe by a selection of variables of our choosing. Any subsequent calculations on our dataframe will first adhere to our chosen grouping. (For example I could group a dataframe on height in genders and group it by sex. Now if we calculate average height there should be one for men and women separately rather than the average height of the entire dataframe)
```

b. Write down what you think the output will look like, then check if you were correct, and describe what arrange() does. Also comment on how it’s different from the group_by() in part (a)?

df |>
  arrange(y)

```{r Tiny dataframe b)}
df |>
  arrange(y)
# It will arrange the dataframe in alphabetical order based on the y variable.
# arrange sorts the dataframe by some sort of numerical or alphabetical order (ascending or descending)
# Its different from group_by since subsequent calculations won't have to first consider the grouping of the y variable
```

c. Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.

df |>
  group_by(y) |>
  summarize(mean_x = mean(x))

```{r Tiny dataframe c)}
# We'll get the x mean based off each group in the y variable. So for example, y has values a & b. we will get respective x means for these values of a & b.
df |>
  group_by(y) |>
  summarize(mean_x = mean(x))
# Groups by y variable first, then calculates the mean in the x variable for each respective value in y.
```

d. Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does. Then, comment on what the message says.

df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

```{r Tiny dataframe d)}
# Groups by y then z. So we have the following pairings of y and z variables: (a, K); (a, L); (b, K). Then we calculate the respective x means
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))
# We get the following message: `summarise()` has grouped output by 'y'. You can override using the `.groups` argument.
# I think this is because for subsequent calculations the group gets "peeled off" so to speak. So after using summarize the dataframe is now only currently grouped by y.
```

e. Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does. How is the output different from the one in part (d).

df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")

```{r Tiny dataframe e)}
# Same output as above.
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x), .groups = "drop")
# the argument `.groups = "drop"` drops the entire grouping. So unlike the above dataframe where it is stilled grouped by the y variable. This dataframe is no longer grouped.
```

f. Write down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does. How are the outputs of the two pipelines different?

df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))

```{r Tiny dataframe f)}
# Same as part d)
df |>
  group_by(y, z) |>
  summarize(mean_x = mean(x))

# This is similar to the above, but instead mean_x will be a newly created column and all other other columns will be present. This means we will get the same number of rows present as in the original dataframe. This is not the case for the summarize function where we only get the grouped variables and the columns we create within the function itself
df |>
  group_by(y, z) |>
  mutate(mean_x = mean(x))
```

